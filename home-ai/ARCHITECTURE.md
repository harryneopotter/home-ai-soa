# üèóÔ∏è SOA1 Home Assistant - System Architecture

**Version**: 1.1  
**Last Updated**: January 1, 2026 (Session 15)  
**Hardware**: Intel X670 + 2x NVIDIA RTX 5060 Ti (16GB each, 32GB total VRAM)

---

## üìã Table of Contents

1. [System Overview](#system-overview)
2. [Core Architecture](#core-architecture)
3. [Orchestrator (Model-Agnostic)](#orchestrator-model-agnostic)
4. [Specialist Agents](#specialist-agents)
5. [Consent Framework](#consent-framework)
6. [GPU Resource Management](#gpu-resource-management)
7. [Data Flow](#data-flow)
8. [Memory System](#memory-system)
9. [API Architecture](#api-architecture)
10. [Future Extensions](#future-extensions)

---

## üéØ System Overview

**SOA1 (Son of Anton)** is a local-first, privacy-focused home assistant system that provides multi-domain assistance through a main orchestrator and specialized agents.

### Design Principles

1. **Privacy-First**: All processing happens locally, no cloud dependencies
2. **Consent-Based**: No specialist actions without explicit user confirmation
3. **Modular**: Specialist agents are independent, swappable modules
4. **Resource-Aware**: Intelligent GPU allocation across specialists
5. **User Agency**: User always has control, silence ‚â† consent
6. **LLM-Driven Communication**: ALL user-facing responses MUST come from LLM, never hardcoded strings (see `RemAssist/LLM_DRIVEN_RESPONSES.md`)

### LLM-Driven Communication Principle (Added Session 15)

**All user-facing text responses MUST be generated by the orchestrator LLM.**

This includes:
- Upload acknowledgments ("I've received your document...")
- Error messages ("I couldn't process that because...")
- Status updates ("Your analysis is ready...")
- Consent requests ("Would you like me to...")

**Why?**
- Consistent communication style across all interactions
- Responses follow orchestrator.md guidelines automatically
- Single source of truth (LLM prompt) for all behavior
- Works identically across all clients (web, mobile, CLI)
- Eliminates frontend/backend string fragmentation

**Implementation:**
- API endpoints that produce user-facing messages MUST call `SOA1Agent.ask()` with appropriate context
- Frontend displays whatever API returns, no fallback strings
- Errors are also routed through LLM for user-friendly formatting

**Reference:** See `RemAssist/LLM_DRIVEN_RESPONSES.md` for full details, anti-patterns, and verification checklist.

### Key Capabilities

- **General Assistance**: Question answering, conversation, memory recall
- **Document Processing**: PDF parsing, summarization, extraction
- **Finance Analysis**: Transaction extraction, spending insights, budgeting
- **Knowledge Management**: (Future) Information organization and retrieval
- **Scheduling**: (Future) Calendar and reminder management
- **Budgeting**: (Future) Budget planning and tracking

---

## üèõÔ∏è Core Architecture

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                        SOA1 HOME ASSISTANT                       ‚îÇ
‚îÇ                                                                  ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ
‚îÇ  ‚îÇ         Orchestrator (Model-Agnostic, GPU 0)          ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  - Main conversation interface                          ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  - Intent classification & routing                      ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  - Consent enforcement                                  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  - Context management                                   ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  - Memory integration                                   ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  - System prompt: soa1/prompts/orchestrator.md          ‚îÇ    ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ
‚îÇ                 ‚îÇ                                               ‚îÇ
‚îÇ                 ‚îÇ Routes to Specialists                          ‚îÇ
‚îÇ                 ‚ñº                                               ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ              SPECIALIST AGENTS                            ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ                                                           ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ Finance (GPU 1)     ‚îÇ  ‚îÇ Budgeting (Future)       ‚îÇ  ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ - phinance-json     ‚îÇ  ‚îÇ - Budget planning        ‚îÇ  ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ - Transaction parse ‚îÇ  ‚îÇ - Expense tracking       ‚îÇ  ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ - Spending insights ‚îÇ  ‚îÇ - Savings goals          ‚îÇ  ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ                                                           ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ Knowledge (Future)  ‚îÇ  ‚îÇ Scheduler (Future)       ‚îÇ  ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ - Info management   ‚îÇ  ‚îÇ - Calendar integration   ‚îÇ  ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ - Document indexing ‚îÇ  ‚îÇ - Reminders              ‚îÇ  ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ - Q&A retrieval     ‚îÇ  ‚îÇ - Task management        ‚îÇ  ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ                                                                  ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ              SUPPORT SYSTEMS                              ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  - Memory Layer (long-term context)                       ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  - Orchestrator (consent & state management)              ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  - PDF Parser (document ingestion)                        ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  - Storage (SQLite, merchant dictionary)                  ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üß† Orchestrator (Model-Agnostic)

### Role & Responsibilities

**The orchestrator is NOT a domain specialist** - it is the **main conversational orchestrator** that:

1. **Engages with users** in natural conversation
2. **Understands intent** through conversation analysis
3. **Routes requests** to appropriate specialist agents
4. **Enforces consent** before invoking specialists
5. **Maintains context** across multi-domain conversations
6. **Synthesizes results** from multiple specialists
7. **Manages memory** for long-term user context

### Key Characteristics

- **Model**: User-swappable (currently NemoAgent, but any model can be used)
- **GPU Assignment**: GPU 0 (primary, 16GB VRAM)
- **Temperature**: 0.3 (balanced between creativity and consistency)
- **Max Tokens**: 512 (concise responses)
- **System Prompt**: Model-agnostic, loaded at runtime from `soa1/prompts/orchestrator.md`

### ‚ö†Ô∏è IMPORTANT: No Modelfile for Orchestrator

**DO NOT create a `.modelfile` for the orchestrator.**

- User will frequently swap orchestrator models for testing
- System prompt must work with ANY model (Nemotron, Llama, Qwen, Mistral, etc.)
- Prompt is injected via Ollama API's `system` parameter at runtime
- This allows hot-swapping models without rebuilding

**phinance-json DOES use a Modelfile** (it's a fixed specialist, not user-swappable).

### When Orchestrator Handles Directly

- General questions (weather, facts, advice)
- Simple document Q&A (already parsed)
- Memory recall queries
- Conversational engagement
- Follow-up questions on specialist results

### When Orchestrator Delegates

- **Finance specialist**: Transaction analysis, spending insights, budgeting
- **Budgeting specialist** (future): Budget planning, expense tracking
- **Knowledge specialist** (future): Deep document indexing, cross-reference
- **Scheduler specialist** (future): Calendar operations, reminders

### Decision Logic

```python
if user_intent == "question_only":
    answer_directly()
elif user_intent == "specialist_analysis":
    if user_confirmed_consent:
        route_to_specialist()
    else:
        ask_for_consent()
else:
    clarify_intent()
```

---

## üéì Specialist Agents

### Design Philosophy

Specialists are **callable modules**, NOT autonomous agents. They:

- ‚úÖ Accept structured input only
- ‚úÖ Perform a single, scoped task
- ‚úÖ Return structured output
- ‚úÖ Remain silent otherwise
- ‚ùå Do NOT handle user intent
- ‚ùå Do NOT ask questions
- ‚ùå Do NOT enforce consent
- ‚ùå Do NOT orchestrate workflows
- ‚ùå Do NOT communicate directly with users

### 1. Finance Specialist (Phinance)

**Status**: ‚úÖ **OPERATIONAL** (as of December 25, 2025)

**Purpose**: Financial document analysis and spending insights

**Model**: `phinance-json` (custom Modelfile)
- Base: Phinance-Phi-3.5-mini-instruct-finance-v0.2
- Temperature: 0.05 (deterministic)
- Format: JSON enforced
- GPU Assignment: GPU 1 (16GB VRAM)

**Input Schema**:
```json
{
  "currency": "USD",
  "transactions": [
    {
      "date": "2024-12-20",
      "merchant": "Whole Foods",
      "amount": 127.43,
      "category": "groceries"
    }
  ],
  "user_request": "Analyze my spending patterns"
}
```

**Output Schema**:
```json
{
  "insights": ["The majority of spending is on travel."],
  "recommendations": ["Review and consolidate travel expenses."],
  "potential_savings": 0.45
}
```

**Components**:
- `home-ai/agents/phinance_adapter.py` - Payload builder
- `home-ai/finance-agent/src/parser.py` - PDF transaction extraction
- `home-ai/finance-agent/src/models.py` - Ollama client wrapper
- `home-ai/finance-agent/src/sanitizer.py` - JSON validation/repair
- `home-ai/finance-agent/src/analyzer.py` - Merchant categorization

**Invocation Flow**:
```
User uploads PDF ‚Üí NemoAgent reads structure ‚Üí Offers finance analysis
‚Üí User confirms ‚Üí PDF Parser extracts transactions ‚Üí Phinance analyzes
‚Üí NemoAgent presents insights to user
```

### 2. Budgeting Specialist

**Status**: ‚è≥ **PLANNED**

**Purpose**: Budget planning, expense tracking, savings goals

**Planned Capabilities**:
- Monthly/weekly budget creation
- Category-based spending limits
- Savings goal tracking
- Budget vs actual analysis
- Alerts for overspending

**File Location**: `home-ai/agents/budgeting_agent.py` (currently empty)

### 3. Knowledge Specialist

**Status**: ‚è≥ **PLANNED**

**Purpose**: Deep document indexing, cross-document reasoning, information retrieval

**Planned Capabilities**:
- Document embedding and semantic search
- Cross-document fact extraction
- Knowledge graph construction
- Contradiction detection
- Source attribution

**File Location**: `home-ai/agents/knowledge_agent.py` (currently empty)

### 4. Scheduler Specialist

**Status**: ‚è≥ **PLANNED**

**Purpose**: Calendar management, reminders, task tracking

**Planned Capabilities**:
- Calendar event creation/editing
- Reminder management
- Task list integration
- Scheduling conflict detection
- Natural language date parsing

**File Location**: `home-ai/agents/scheduler_agent.py` (currently empty)

---

## üîí Consent Framework

### Core Invariant

> **The assistant MUST NOT initiate any specialist action unless the user has explicitly requested or confirmed it.**

### What Requires Consent

- Financial analysis
- Deep categorization
- Report generation
- Cross-document reasoning
- Any specialist invocation

### What Does NOT Require Consent

- File ingestion
- Metadata extraction (filename, size, page count)
- Header/first-page parsing
- Structural reading
- Indexing text for Q&A
- Preparing options (not executing them)

### Consent Language

**‚úÖ Allowed**:
- "Do you want me to..."
- "If you like, I can..."
- "I can prepare X if that helps"

**‚ùå Forbidden**:
- "I'll go ahead and..."
- "I'll proceed with..."
- "Next, I will..."
- "I've started analyzing..."

### Implementation

Enforced by `home-ai/soa1/orchestrator.py`:

```python
class ConsentState:
    user_action_confirmed: bool = False
    confirmed_intent: Optional[UserIntent] = None
    confirmed_specialists: Set[str] = set()

def require_consent(specialist_name: str):
    if not can_invoke_specialist(specialist_name):
        raise PermissionError(f"Consent missing for: {specialist_name}")
```

### Rules

1. **Silence ‚â† Consent**: No action without explicit confirmation
2. **Upload ‚â† Consent**: Receiving files doesn't mean process them
3. **Document Type ‚â† Consent**: Detecting finance PDF doesn't trigger analysis
4. **Intent ‚â† Action**: Understanding what user wants ‚â† doing it

Reference: `/home/ryzen/projects/RemAssist/IMPLEMENTATION_GUIDE.md`

---

## üñ•Ô∏è GPU Resource Management

### Hardware Configuration

- **Total VRAM**: 32GB (2x 16GB)
- **Platform**: Intel X670
- **CUDA Version**: 12.6
- **Driver**: 580.95.05

### GPU Allocation Strategy

| GPU | Assignment | Model | VRAM | Purpose |
|-----|-----------|-------|------|---------|
| GPU 0 | Orchestrator | User-swappable (NemoAgent, etc.) | ~8-9 GB | Main conversation, routing, context |
| GPU 1 | Specialist Models | phinance-json (2.2 GB) | 2.2 GB | Finance analysis (+ future specialists) |

### Model Loading Strategy

**Current Implementation** (via Ollama):
- Models loaded on-demand by Ollama
- Automatic GPU selection by Ollama
- No explicit GPU pinning in application code

**Future Enhancement**:
- Explicit CUDA device assignment
- Model pre-loading for latency reduction
- Dynamic specialist swapping on GPU 1
- Resource-aware scheduling

### VRAM Headroom

- GPU 0: 16GB - 8.7GB = **7.3 GB free** (47% utilization)
- GPU 1: 16GB - 2.2GB = **13.8 GB free** (14% utilization)

**Capacity for future specialists** on GPU 1:
- Could load 6x phinance-sized models (2.2 GB each)
- Or 1x 14B model for knowledge/reasoning
- Or multiple 7B specialists simultaneously

---

## üîÑ Data Flow

### Conversation Flow

```
1. User sends query
   ‚Üì
2. NemoAgent receives query
   ‚Üì
3. Memory system searches relevant context
   ‚Üì
4. NemoAgent + memory context ‚Üí classify intent
   ‚Üì
5a. If question_only ‚Üí Answer directly
5b. If specialist_analysis ‚Üí Check consent
   ‚Üì
6. If consent granted ‚Üí Route to specialist
   ‚Üì
7. Specialist processes and returns structured data
   ‚Üì
8. NemoAgent synthesizes response
   ‚Üì
9. Write interaction to memory
   ‚Üì
10. Return response to user
```

### Finance Pipeline Flow

```
1. User uploads PDF statement
   ‚Üì
2. Orchestrator: files received, reading structure
   ‚Üì
3. NemoAgent: offers intent options (question, summary, finance analysis)
   ‚Üì
4. User: "analyze my spending" (implicit finance intent)
   ‚Üì
5. Orchestrator: asks for consent
   ‚Üì
6. User: "yes" / "proceed"
   ‚Üì
7. Orchestrator: grants consent to phinance specialist
   ‚Üì
8. PDF Parser: extracts transactions (regex + LLM fallback)
   ‚Üì
9. Phinance Adapter: builds structured payload
   ‚Üì
10. Phinance Model: generates insights (GPU 1)
    ‚Üì
11. Sanitizer: validates/repairs JSON output
    ‚Üì
12. Storage: saves transactions.json + analysis.json
    ‚Üì
13. NemoAgent: presents insights to user
    ‚Üì
14. User can ask follow-up questions (context retained)
```

---

## üß† Memory System

### Purpose

Long-term episodic memory for user context across sessions.

### Architecture

**Backend**: MemLayer (separate service on port 8000)
- Vector database for semantic search
- Metadata storage (timestamps, event types)
- User/profile isolation

**Integration**: `home-ai/soa1/memory.py`
```python
class MemoryClient:
    def search_memory(query: str) -> List[Dict]:
        # Search relevant past memories
        
    def write_memory(text: str, metadata: Dict):
        # Store new factual memory
        
    def health_check() -> bool:
        # Verify service availability
```

### Memory Format

```python
{
    "text": "[Event]\nquestion: ...\nanswer: ...\nrecorded_at_utc: ...",
    "metadata": {
        "event_type": "qa_interaction",
        "recorded_at_utc": "2025-12-25T02:59:00Z",
        "recorded_epoch": 1735094340
    },
    "timestamp": "2025-12-25T02:59:00Z"
}
```

### Usage Patterns

- **Before answering**: Search memories for relevant context
- **After answering**: Write interaction to memory
- **Graceful degradation**: Continue if memory service unavailable
- **Time awareness**: All memories include explicit timestamps

---

## üåê API Architecture

### SOA1 API Service

**Port**: 8001  
**Framework**: FastAPI  
**Location**: `home-ai/soa1/api.py`

**Endpoints**:

| Endpoint | Method | Purpose | Rate Limit |
|----------|--------|---------|------------|
| `/ask` | POST | Query NemoAgent | 100/min |
| `/ask-with-tts` | POST | Query with audio response | 20/min |
| `/upload` | POST | PDF upload for processing | 10/min |
| `/health` | GET | Service health check | Unlimited |

**Request Schema**:
```json
{
  "query": "What did I spend on groceries?",
  "context": "optional additional context"
}
```

**Response Schema**:
```json
{
  "answer": "Based on your Chase statement...",
  "used_memories": [
    {"text": "...", "timestamp": "..."}
  ]
}
```

**Error Handling**:
- Standardized error responses with error codes
- Comprehensive validation (input, files, queries)
- Service error isolation (memory, model, TTS)
- Client IP tracking in logs

**Security**:
- IP whitelisting (Tailscale network)
- Rate limiting (token bucket algorithm)
- Input validation (Pydantic models)
- Request size limits

Reference: `home-ai/soa1/utils/errors.py`, `home-ai/soa1/utils/rate_limiter.py`

---

## üîÆ Future Extensions

### Planned Features

1. **Multi-User Support**
   - Per-user memory isolation
   - Household access controls
   - Role-based permissions (admin vs member)

2. **Voice Interface**
   - TTS integration (VibeVoice)
   - Voice command processing
   - Multi-speaker TTS

3. **Mobile Companion**
   - iOS/Android app
   - Push notifications
   - Remote access via Tailscale

4. **Advanced Specialists**
   - Medical document analysis
   - Legal document review
   - Home automation integration

5. **Self-Optimizing System**
   - Daytime: Fast 7B models for immediate tasks
   - Nighttime: 14-32B models audit decisions, correct errors
   - Resource-aware scheduling (learn quiet hours)
   - Unified logging with confidence scores

6. **Monitoring Dashboard**
   - Active/inactive services with real-time status
   - Model logs and error tracking
   - Loaded models (Ollama list with GPU assignments)
   - GPU utilization and VRAM usage
   - Service health metrics (uptime, response times)
   - Recent API calls and request logs
   - System resources (CPU, memory, disk)
   - Model inference statistics (latency, throughput)

### Extension Points

**Adding a New Specialist**:

1. Create specialist agent in `home-ai/agents/new_specialist_agent.py`
2. Define input/output schemas (dataclasses)
3. Create adapter function for payload building
4. Add specialist to NemoAgent's system prompt
5. Update orchestrator intent classification
6. Create Modelfile if using specialized model
7. Update this architecture document

**Example Skeleton**:
```python
# home-ai/agents/medical_specialist.py

from dataclasses import dataclass
from typing import List

@dataclass
class MedicalDocument:
    doc_type: str  # lab_report, prescription, imaging
    date: str
    provider: str
    content: str

@dataclass
class MedicalInsight:
    summary: str
    key_findings: List[str]
    action_items: List[str]
    confidence: float

def analyze_medical_document(doc: MedicalDocument) -> MedicalInsight:
    """Analyze medical document (requires consent)"""
    # Implementation
    pass
```

---

## üìö Related Documentation

- **Implementation Guide**: `/home/ryzen/projects/RemAssist/IMPLEMENTATION_GUIDE.md`
- **File Checklists**: `/home/ryzen/projects/RemAssist/FILE_CHECKLISTS.md`
- **Services Config**: `/home/ryzen/projects/RemAssist/SERVICES_CONFIG.md`
- **Next Tasks**: `/home/ryzen/projects/RemAssist/NEXT_TASKS.md`
- **Session History**: `/home/ryzen/projects/RemAssist/History.md`
- **Finance MVP Plan**: `/home/ryzen/projects/RemAssist/FINANCE_MVP_PLAN_V2.md`

---

## üéØ Summary

**SOA1** is a modular, consent-based home assistant with:

- **Orchestrator**: Model-agnostic main orchestrator on GPU 0 (conversation, routing, consent)
- **Specialists**: Domain experts on GPU 1 (finance operational, others planned)
- **Memory System**: Long-term episodic context
- **Consent Framework**: User agency, no surprises
- **Local-First**: Privacy-focused, no cloud dependencies
- **Resource-Aware**: Intelligent GPU allocation, 32GB VRAM total

**Current Status** (January 1, 2026):
- ‚úÖ Finance specialist operational (phinance-json)
- ‚úÖ Consent framework implemented
- ‚úÖ PDF parsing pipeline working
- ‚úÖ SSE event streaming for analysis progress
- ‚úÖ Per-step timing instrumentation
- ‚úÖ Monitoring dashboard at /monitoring
- ‚úÖ Dashboard JSON converter integrated
- ‚úÖ Orchestrator system prompt at `soa1/prompts/orchestrator.md`
- ‚úÖ SQLite persistence for transactions
- ‚úÖ LLM-driven responses (all user-facing text from agent)
- ‚úÖ Chat history persistence with multi-turn context
- ‚úÖ Cross-document comparison and merchant normalization
- ‚è≥ Other specialists planned but not implemented

**Next Steps**:
1. **Security Layer**: PII redaction + encrypted storage (see `RemAssist/PROGRESSIVE_BATCH_ARCHITECTURE.md`)
2. **Batch Processing**: Progressive 5-phase pipeline for multi-PDF uploads
3. **Output Pre-generation**: Dashboard, PDF, infographic prompts ready before user asks
4. Implement remaining specialists (budgeting, knowledge, scheduler)

---

*This document is maintained alongside system development. Update after major architectural changes.*
